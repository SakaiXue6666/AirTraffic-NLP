"""
Date: 2021-06-02 00:33:09
LastEditors: GodK
"""
import sys

sys.path.append("../")
from common.utils_lower import Preprocessor
import torch
import numpy as np
from torch.utils.data import DataLoader, Dataset
import torch.nn as nn
import torch.nn.functional as F
import random

class MyDataset(Dataset):
    def __init__(self, data):
        self.data = data
        self.length = len(data)

    def __getitem__(self, index):
        return self.data[index]

    def __len__(self):
        return self.length


class DataMaker(object):
    def __init__(self, tokenizer, add_special_tokens=True):
        super().__init__()
        self.tokenizer = tokenizer
        self.add_special_tokens = add_special_tokens
        self.preprocessor = Preprocessor(tokenizer, self.add_special_tokens)

    def augment_data(self, sample, mask_token='[MASK]', data_type="train", arg=True):
        """
        å¯¹æ ·æœ¬è¿›è¡Œæ•°æ®å¢å¼ºï¼ˆåœ¨è®­ç»ƒæ—¶ä½¿ç”¨ï¼‰
        train: 50% ä¸å˜ï¼Œ40% æ›¿æ¢ä¸ºå®ä½“åŸåç§°ï¼Œ10% æ›¿æ¢ä¸º [MASK]
        valid: 100% ä¸å˜
        
        Inputs:
        trainå’Œvalidä¸­ä¸€æ¡æ•°æ®æ ¼å¼ï¼š{"text":"...", "label": {label:{entity:[[start, end], ...], ..., "scene": [...]}
        Returns:
        trainå’Œvalidä¸­ä¸€æ¡æ•°æ®æ ¼å¼ï¼š{"text":"...", "entity_list":[(start, end, label), ...], "scene":[...]}
        """
        text = sample['text']
        entity_list = []

        offset = 0
        new_text = text
        modified_text = list(text)
        modified_spans = []

        all_entities = []
        for label_type, entities in sample["label"].items():
            if label_type == "scene":
                scene = sample["label"]["scene"]
                continue
            for ent, positions in entities.items():
                for pos in positions:
                    all_entities.append({
                        "start": pos[0],
                        "end": pos[1],
                        "type": label_type,
                        "text": text[pos[0]:pos[1]+1],
                        "entity_name": ent
                    })

        all_entities.sort(key=lambda x: x["start"])  # æŒ‰èµ·å§‹ä½ç½®æ’åºï¼Œé¿å…ä½ç½®é”™ä¹±

        new_text = ""
        last_idx = 0
        new_entity_list = []

        my_entity_list = {}  # ğŸ‘ˆ

        span_airline_code = []  ###
        set_call_sign = set()  ###
        for ent in all_entities:
            start, end = ent["start"], ent["end"]

            if ent['type'] == 'NER LABEL (call_sign)':  ####
                set_call_sign.add(ent["text"])
                continue

            if data_type == "train" and arg == True:
                # è®­ç»ƒæ—¶ï¼š50%ä¸å˜ï¼Œ40%æ›¿æ¢ä¸ºå®ä½“åï¼Œ10%æ›¿æ¢ä¸º[MASK]
                prob = random.random()

                if prob < 0.5:
                    # ä¸å˜
                    replacement = ent["text"]  ####
                    new_text += text[last_idx:end + 1]
                    new_start = len(new_text) - (end - start + 1)
                    new_end = len(new_text) - 1
                elif prob < 0.5 + 0.4:
                    # æ›¿æ¢ä¸ºå®ä½“åç§° d2
                    replacement = ent["entity_name"]
                    new_text += text[last_idx:start] + replacement
                    new_start = len(new_text) - len(replacement)
                    new_end = len(new_text) - 1
                else:
                    # æ›¿æ¢ä¸º [MASK] d3
                    replacement = mask_token
                    new_text += text[last_idx:start] + replacement
                    new_start = len(new_text) - len(replacement)
                    new_end = len(new_text) - 1

            else:
                # éè®­ç»ƒæ—¶ï¼š100% ä¸å˜
                replacement = ent["text"]  ####
                new_text += text[last_idx:end + 1]
                new_start = len(new_text) - (end - start + 1)
                new_end = len(new_text) - 1

            new_entity_list.append((new_start, new_end, ent["type"]))
            last_idx = end + 1

            if ent["type"] not in my_entity_list:  # ğŸ‘ˆ
                my_entity_list[ent["type"]] = [replacement]
            else:
                my_entity_list[ent["type"]].append(replacement)

            if ent['type'] == 'NER LABEL (icao_code)':  ###
                span_airline_code.append((new_start, new_end, ent["text"], replacement))

        new_text += text[last_idx:]  # åŠ ä¸Šå‰©ä½™éƒ¨åˆ†

        if span_airline_code != [] and set_call_sign != set():  ###
            for new_start, new_end, ent_text, replacement in span_airline_code:
                if ent_text in set_call_sign:
                    new_entity_list.append((new_start, new_end, 'NER LABEL (call_sign)'))

                    if 'NER LABEL (call_sign)' not in my_entity_list:  # ğŸ‘ˆ
                        my_entity_list['NER LABEL (call_sign)'] = [replacement]
                    else:
                        my_entity_list['NER LABEL (call_sign)'].append(replacement)

        return {
            "text": new_text,
            "entity_list": new_entity_list,
            "scene": scene,
            "my_entity_list": my_entity_list, # ğŸ‘ˆ
        }

    def build_prompt(self, text, scene2id, my_entity_list, data_type):
        class_content = '\n'.join([label for label, _ in sorted(scene2id.items(), key=lambda x: x[1])])
        entity_content = "ï¼›".join(
            f"{label}: {'ã€'.join(label_text_list)}"
            for label, label_text_list in my_entity_list.items()
        )

        if data_type != "predict":
            prompt = (
                "<|im_start|>system\n"
                "ä½ æ˜¯ä¸€ä¸ªé£è¡Œä¸ç®¡åˆ¶æ–‡æœ¬çš„å¤šæ ‡ç­¾åˆ†ç±»å™¨ï¼Œä½ ä¼šæ¥æ”¶åˆ°ä¸€æ®µæ–‡æœ¬å’Œå‡ ä¸ªæ½œåœ¨çš„åˆ†ç±»é€‰é¡¹ï¼Œè¯·è¾“å‡ºæ–‡æœ¬å†…å®¹çš„æ­£ç¡®ç±»å‹ã€‚å¤šä¸ªæ ‡ç­¾ç”¨é¡¿å·ã€Œã€ã€åˆ†éš”ã€‚ä¸è¦è¾“å‡ºå¤šä½™å†…å®¹ã€‚\n"
                "<|im_end|>\n"
                "<|im_start|>user\n"
                f"# ç±»åˆ«\n{class_content}\n\n"
                f"# æ–‡æœ¬çš„å®ä½“\n{entity_content}\n\n"
                f"# æ–‡æœ¬\n{text}\n\n"
                "è¯·è¾“å‡ºæ­¤æ–‡æœ¬å¯¹åº”çš„ç±»åˆ«ï¼š\n"
                "<|im_end|>\n"
                "<|im_start|>assistant\n"
            )
        else:
            prompt = (
                "<|im_start|>system\n"
                "ä½ æ˜¯ä¸€ä¸ªé£è¡Œä¸ç®¡åˆ¶æ–‡æœ¬çš„å¤šæ ‡ç­¾åˆ†ç±»å™¨ï¼Œä½ ä¼šæ¥æ”¶åˆ°ä¸€æ®µæ–‡æœ¬å’Œå‡ ä¸ªæ½œåœ¨çš„åˆ†ç±»é€‰é¡¹ï¼Œè¯·è¾“å‡ºæ–‡æœ¬å†…å®¹çš„æ­£ç¡®ç±»å‹ã€‚å¤šä¸ªæ ‡ç­¾ç”¨é¡¿å·ã€Œã€ã€åˆ†éš”ã€‚ä¸è¦è¾“å‡ºå¤šä½™å†…å®¹ã€‚\n"
                "<|im_end|>\n"
                "<|im_start|>user\n"
                f"# ç±»åˆ«\n{class_content}\n\n"
                "# æ–°å¢ç¤ºä¾‹\næ–‡æœ¬çš„å®ä½“ï¼š<NER LABEL 1>ï¼š<NER TEXT>ï¼›<NER LABEL 2>ï¼š<NER TEXT>ã€‚æ–‡æœ¬ï¼š<TEXT>ã€‚æ­¤æ–‡æœ¬å¯¹åº”ç±»åˆ«ï¼š<CLS LABEL N+1>ã€‚\n\n"
                f"# æ–‡æœ¬çš„å®ä½“\n{entity_content}\n\n"
                f"# æ–‡æœ¬\n{text}\n\n"
                "è¯·è¾“å‡ºæ­¤æ–‡æœ¬å¯¹åº”çš„ç±»åˆ«ï¼š\n"
                "<|im_end|>\n"
                "<|im_start|>assistant\n"
            )

        return prompt

    def generate_inputs(self, datas, max_seq_len, ent2id, scene2id, data_type="train"):
        """ç”Ÿæˆå–‚å…¥æ¨¡å‹çš„æ•°æ®

        Args:
            datas (list): jsonæ ¼å¼çš„æ•°æ®[{'text':'','entity_list':[(start,end,ent_type),()]}]
            max_seq_len (int): å¥å­æœ€å¤§tokenæ•°é‡
            ent2id (dict): entåˆ°idçš„æ˜ å°„
            data_type (str, optional): dataç±»å‹. Defaults to "train".

        Returns:
            list: [(sample, input_ids, attention_mask, token_type_ids, labels),(),()...]

        å°† labels æ”¹ä¸ºä¸€ä¸ª å­—å…¸ç»“æ„
        labels = {
            "ner": å®ä½“è¯†åˆ«æ ‡ç­¾å¼ é‡,  # shape: (ent_type_size, max_len, max_len)
            "scene": åœºæ™¯å¤šæ ‡ç­¾åˆ†ç±»å¼ é‡  # shape: (scene_type_size,)
        }

        """

        ent_type_size = len(ent2id)  # å®ä½“ç±»åˆ«
        scene_type_size = len(scene2id)

        all_inputs = []
        for sample in datas:
            #if data_type != "predict":
            sample = self.augment_data(sample, data_type=data_type)

            sample["text"] = self.build_prompt(sample["text"], scene2id, sample["my_entity_list"], data_type=data_type)  # ğŸ‘ˆ

            labels = None
            if data_type != "predict":
                scene_labels = []
                for scene_label in sample.get("scene", []):
                    scene_labels.append(scene_label)
                scene_labels = 'ã€'.join(scene_labels)

                labels = {
                    # "ner": torch.tensor(ner_labels).clone().detach().long(),
                    # "scene": torch.tensor(scene_labels).clone().detach().float()  # å¤šæ ‡ç­¾åˆ†ç±»ä¸€èˆ¬ç”¨float
                    "scene": scene_labels
                }

            sample_input = {
                "sample": sample,
                "text": sample["text"],
                "labels": labels,
            }

            all_inputs.append(sample_input)
        return all_inputs

    def generate_batch(self, batch_data, max_seq_len, ent2id, scene2id, data_type="train", task_type="classification"):
        '''
        list: [(sample, text, labels), ...]
            sample: ...
            text: "prompt..."
            labels: {"scene": "label1ã€label2ã€..."}
        '''
        batch_data = self.generate_inputs(batch_data, max_seq_len, ent2id, scene2id, data_type)
        sample_list = []
        text_list = []

        ner_labels_list = []
        scene_labels_list = []

        for sample in batch_data:
            sample_list.append(sample["sample"])
            text_list.append(sample["text"])
            if data_type != "predict":
                # labels_list.append(sample[4])
                # ner_labels_list.append(sample["labels"]["ner"])
                scene_labels_list.append(sample["labels"]["scene"])

        is_lm_output = data_type != "predict" and not(data_type == "valid" and task_type=="classification")
        im_end_id = self.tokenizer.convert_tokens_to_ids("<|im_end|>") if "<|im_end|>" in self.tokenizer.get_vocab() else self.tokenizer.eos_token_id

        # ğŸ” åœ¨è¿™é‡Œè¿›è¡Œ batched tokenization
        inputs = self.tokenizer(
            text_list,
            add_special_tokens=False,
        )

        if is_lm_output:
            outputs = self.tokenizer(
                scene_labels_list,
                add_special_tokens=False,
            )

        batch_input_ids = []
        batch_attention_mask = []
        batch_labels = []

        for i in range(len(inputs['input_ids'])):
            if is_lm_output:
                inputs_ids = inputs['input_ids'][i] + outputs['input_ids'][i] + [im_end_id]
                attention_mask = inputs['attention_mask'][i] + outputs['attention_mask'][i] + [1]
                labels = [-100] * len(inputs['input_ids'][i]) + outputs['input_ids'][i] + [im_end_id]  # causal lm çš„æ ‡ç­¾ä¸­ï¼Œprompt éƒ¨åˆ†ä¸º -100
            else :
                inputs_ids = inputs['input_ids'][i]
                attention_mask = inputs['attention_mask'][i]

            # æˆªæ–­
            if len(inputs_ids) > max_seq_len:
                inputs_ids = inputs_ids[:max_seq_len]
                attention_mask = attention_mask[:max_seq_len]
                if is_lm_output:
                    labels = labels[:max_seq_len]

            batch_input_ids.append(inputs_ids)
            batch_attention_mask.append(attention_mask)
            if is_lm_output:
                batch_labels.append(labels)

        # Step 4: Pad to the longest sequence in batch
        longest = max(len(ids) for ids in batch_input_ids)
        for i in range(len(batch_input_ids)):
            batch_input_ids[i] = [self.tokenizer.pad_token_id] * (longest - len(batch_input_ids[i])) + batch_input_ids[i]
            batch_attention_mask[i] = [0] * (longest - len(batch_attention_mask[i])) + batch_attention_mask[i]
            if is_lm_output:
                batch_labels[i] = [-100] * (longest - len(batch_labels[i])) + batch_labels[i]


        # Convert to tensors
        batch_input_ids = torch.tensor(batch_input_ids, dtype=torch.long)
        batch_attention_mask = torch.tensor(batch_attention_mask, dtype=torch.long)
        batch_labels = torch.tensor(batch_labels, dtype=torch.long) if is_lm_output else None

        return (
            sample_list,
            batch_input_ids,
            batch_attention_mask,
            None,  # token_type_ids not used
            batch_labels,
            scene_labels_list if data_type != "predict" else None,
        )


    def decode_ent(self, pred_matrix):
        pass



class MetricsCalculator(object):
    def __init__(self):
        super().__init__()

    def get_sample_f1(self, y_pred, y_true):
        """
        å¤šæ ‡ç­¾ scene åˆ†ç±»çš„ F1ï¼ˆmicroï¼‰
        """
        y_pred = torch.gt(y_pred, 0).clone().detach().float()
        return 2 * torch.sum(y_true * y_pred) / (torch.sum(y_true + y_pred) + 1e-10)

    def get_sample_precision(self, y_pred, y_true):
        y_pred = torch.gt(y_pred, 0).clone().detach().float()
        return torch.sum(y_pred[y_true == 1]) / (y_pred.sum() + 1e-10)

    def get_sample_recall(self, y_pred, y_true):
        y_pred = torch.gt(y_pred, 0).clone().detach().float()
        return torch.sum(y_pred[y_true == 1]) / (y_true.sum() + 1e-10)

    def get_scene_metrics(self, predict_labels, true_labels, scene_type_size, scene2id):
        """
        å¤šæ ‡ç­¾ scene åˆ†ç±»çš„æ•´ä½“ F1, P, Rï¼ˆmicroï¼‰
        Args:
            predict_labels: [[label1, label2, ...], ...]
            true_labels: [[label1, label2, ...], ...]
        """
        batch_size = len(predict_labels)
        pred_ids = [[scene2id[label] for label in labels if label in scene2id] for labels in predict_labels]
        true_ids = [[scene2id[label] for label in labels if label in scene2id] for labels in true_labels]

        y_pred = torch.zeros(batch_size, scene_type_size)
        y_true = torch.zeros(batch_size, scene_type_size)

        for i in range(batch_size):
            if pred_ids[i]:
                y_pred[i, pred_ids[i]] = 1
            if true_ids[i]:
                y_true[i, true_ids[i]] = 1

        f1 = self.get_sample_f1(y_pred, y_true)
        precision = self.get_sample_precision(y_pred, y_true)
        recall = self.get_sample_recall(y_pred, y_true)
        return f1.item(), precision.item(), recall.item()

    def get_evaluate_fpr(self, y_pred, y_true, threshold=0):
        """
        NER çš„ F1ã€Precisionã€Recall
        """
        y_pred = y_pred.cpu().numpy()
        y_true = y_true.cpu().numpy()
        pred = []
        true = []
        for b, l, start, end in zip(*np.where(y_pred > threshold)):
            pred.append((b, l, start, end))
        for b, l, start, end in zip(*np.where(y_true > 0)):
            true.append((b, l, start, end))

        R = set(pred)
        T = set(true)
        X = len(R & T)
        Y = len(R)
        Z = len(T)
        f1 = 2 * X / (Y + Z + 1e-10)
        precision = X / (Y + 1e-10)
        recall = X / (Z + 1e-10)
        return f1, precision, recall

    def decode_scene(self, logits_scene, threshold=0):
        # probs = torch.sigmoid(logits_scene)
        preds = (logits_scene > threshold).int().cpu().numpy()
        results = []
        for pred_vec in preds:
            labels = [scene_label for i, scene_label in enumerate(self.id2scene.values()) if pred_vec[i] == 1]
            results.append(labels)
        return results